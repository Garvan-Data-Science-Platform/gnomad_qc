"""Produce per-exome stats, per-genome stats, and variant type counts for v4."""
import argparse
import logging

import hail as hl
# from gnomad.assessment.summary_stats import (
#     default_generate_gene_lof_matrix,
#     default_generate_gene_lof_summary,
#     get_summary_counts,
# )
from gnomad.resources.resource_utils import (
    TableResource,
    VersionedTableResource,
)
# from gnomad.utils.filtering import filter_to_adj
from gnomad.utils.slack import slack_notifications

from gnomad_qc.slack_creds import slack_token
from gnomad_qc.v4.resources.basics import (
    calling_intervals,
    get_gnomad_v4_vds,
)
import gnomad_qc.v4.resources.meta as meta
from gnomad_qc.v4.resources.release import (
    release_sites,
    CURRENT_RELEASE,
    RELEASES,
    _release_root
)


logging.basicConfig(
    format="%(asctime)s (%(name)s %(lineno)s): %(message)s",
    datefmt="%m/%d/%Y %I:%M:%S %p",
)
logger = logging.getLogger("release")
logger.setLevel(logging.INFO)


def get_per_sample_variant_counts(
    test: bool = False, data_type: str = "exomes"
) -> VersionedTableResource:
    """
    Get per-sample variant counts and other information as generated by Hail's Sample QC module.

    :param test: Whether to use a tmp path for analysis of the test VDS instead of the full v4 VDS
    :param data_type: Data type used in sample QC, e.g. "exomes" or "genomes"
    :return: Per sample variant counts table
    """
    return VersionedTableResource(
        CURRENT_RELEASE,
        {
            version: TableResource(
                f"{_release_root(version=version, test=test, data_type=data_type, extension='ht')}/gnomad.{data_type}.v{version}.per_sample_variant_counts.ht"
            )
            for version in RELEASES
        },
    )


def per_sample_datatype(
    data_type: str = "exomes",
    test: bool = False,
    overwrite: bool = False,
    filter_variant_qc: bool = False,
    filter_calling_intervals: bool = False,
) -> None:
    """
    Write out Hail's sample_qc output for desired samples and variants.
    Useful for finding the amount of variants (total or specific types) per sample.
    Also prints distribution of total variants called per sample.

    :param data_type: String of either "exomes" or "genomes" for the sample type.
    :param test: Boolean for if you would like to use a small test set.
    :param overwrite: Boolean to overwrite checkpoint files if requested.
    :param filter_variant_qc: Bool to only count variants that pass all variant qc filters (i.e. VQSR, AC0).
    :param filter_calling_intervals: Bool to filter only to variants in calling intervals.
    """

    # Read in release data and metadata and VDS
    ht_release_data = release_sites(data_type).ht()
    if test:
        logger.info("Test: filtering to only chr22 sites and 467 test samples in VDS")
        ht_release_data = ht_release_data.filter(
            ht_release_data.locus.contig == "chr22"
        )

    if filter_variant_qc:
        logger.info("Filter to those which pass all filters")
        ht_release_data = ht_release_data.filter(hl.len(ht_release_data.filters) == 0)

    if filter_calling_intervals:
        logger.info("Filter to calling intervals")
        calling_interval_ht = calling_intervals(
            interval_name="union",
            calling_interval_padding=0,
        ).ht()
        ht_release_data = ht_release_data.filter(
            ~hl.is_missing(calling_interval_ht[ht_release_data.locus])
        )

    meta_ht = meta(data_type=data_type).ht()
    vds_data = get_gnomad_v4_vds(test=test, release_only=True)
    vds_data_mt = vds_data.variant_data

    # Filter to only variants and samples in release data
    vds_data_filtered = vds_data_mt.filter_rows(
        ~hl.is_missing(ht_release_data[vds_data_mt.row_key])
    )

    vds_data_filtered = vds_data_filtered.filter_cols(
        meta_ht[vds_data_filtered.s].release
    )

    # Select data down to: only variant locus & alleles and only if samples do or don't have it
    # Create then select down to GT
    vds_data_filtered = vds_data_filtered.annotate_entries(
        GT=hl.vds.lgt_to_gt(vds_data_filtered.LGT, vds_data_filtered.LA)
    )
    vds_data_filtered = vds_data_filtered.select_entries("GT")
    vds_data_filtered = vds_data_filtered.select_rows()
    vds_data_filtered = vds_data_filtered.select_cols()

    # Perform Hail's Sample QC module
    # Resulting table is of most interest for further analysis
    # Write said table out to determined path
    sample_qc_ht = hl.sample_qc(vds_data_filtered).cols().key_by("s")
    sample_qc_ht = sample_qc_ht.checkpoint(
        get_per_sample_variant_counts(test=test, data_type=data_type).path,
        overwrite=overwrite,
    )

    # Column 'n_called' is a per-sample metric of the number of variants called
    # Report some stats of interest from this table
    called_per_distribution = sample_qc_ht.aggregate(
        hl.agg.approx_quantiles(
            sample_qc_ht.sample_qc.n_called, qs=[0, 0.25, 0.50, 0.75, 1.0]
        )
    )

    logger.info(
        f"Quantiles called per {data_type} by 0th, 25th, 50th, 75th, and 100th"
        f" quantiles \n: {called_per_distribution}"
    )


def variant_types():
    # what is needed: stats from your notebook for:
    # Indels and Snps per data type
    # How many (number and proportion) pass VQSR and pass All Filters
    pass


def vep_consequences():
    # what is needed: stats from notebook for:
    # VEP consequence breakdown , in those two different returns
    # let users specify: pass all filters, pass VQSR, or all variants
    pass


def main(args):
    """Collect summary stats of gnomAD v4 data."""
    hl.init(
        log="/per_exome.log",
        default_reference="GRCh38",
        tmp_dir="gs://gnomad-tmp-30day",
    )
    # SSA Logs are easier to troubleshoot with.
    hl._set_flags(use_ssa_logs="1")

    data_type = args.data_type
    test = args.test
    overwrite = args.overwrite
    per_sample_filter_variant_qc = args.per_sample_filter_variant_qc
    per_sample_filter_calling_intervals = args.per_sample_filter_calling_intervals

    if args.get_per_sample:
        per_sample_datatype(
            data_type=data_type,
            test=test,
            overwrite=overwrite,
            filter_variant_qc=per_sample_filter_variant_qc,
            filter_calling_intervals=per_sample_filter_calling_intervals,
        )


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-o",
        "--overwrite",
        help="Overwrite data (default: False)",
        action="store_true",
    )
    parser.add_argument(
        "--slack-channel", help="Slack channel to post results and notifications to."
    )
    parser.add_argument(
        "--test",
        help="Test on a small number of variants",
        action="store_true",
    )
    parser.add_argument(
        "--get-summary-counts",
        help="Get summary counts per variant category.",
        action="store_true",
    )
    parser.add_argument(
        "--get-per-sample",
        help="Get variants per sample data type.",
        action="store_true",
    )
    parser.add_argument(
        "--data-type",
        default="exomes",
        choices=["exomes", "genomes"],
        help="Data type (exomes or genomes) to produce summary stats for.",
    )
    parser.add_argument(
        "--per-sample-filter-variant-qc",
        help=(
            "Only calculate per-sample variants for those variants that pass all"
            " variant qc filters."
        ),
        action="store_true",
    )
    parser.add_argument(
        "--per-sample-filter-calling-intervals",
        help=(
            "Only calculate per-sample variants for those variants inside of calling"
            " intervals."
        ),
        action="store_true",
    )
    args = parser.parse_args()

    if args.slack_channel:
        with slack_notifications(slack_token, args.slack_channel):
            main(args)
    else:
        main(args)
